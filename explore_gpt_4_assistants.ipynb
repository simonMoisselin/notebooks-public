{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import openai\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "# assert version is > 1.0.0\n",
    "assert openai.__version__ > \"1.0.0\", \"Please upgrade the OpenAI Python client: pip install -U openai\"\n",
    "print(openai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files for context of the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 228 python files\n",
      "Files with model in the path\n",
      "['data/tinygrad/test/models/test_real_world.py', 'data/tinygrad/test/models/test_train.py', 'data/tinygrad/test/models/test_end2end.py', 'data/tinygrad/test/models/test_onnx.py', 'data/tinygrad/test/models/test_mnist.py', 'data/tinygrad/test/models/test_efficientnet.py', 'data/tinygrad/test/models/test_whisper.py', 'data/tinygrad/test/models/test_waifu2x.py', 'data/tinygrad/test/models/test_rnnt.py', 'data/tinygrad/test/models/test_bert.py', 'data/tinygrad/test/extra/test_export_model.py', 'data/tinygrad/test/external/external_model_benchmark.py', 'data/tinygrad/test/external/external_test_jit_on_models.py', 'data/tinygrad/test/external/external_test_allocator_on_models.py', 'data/tinygrad/models/unet3d.py', 'data/tinygrad/models/efficientnet.py', 'data/tinygrad/models/vit.py', 'data/tinygrad/models/resnet.py', 'data/tinygrad/models/transformer.py', 'data/tinygrad/models/mask_rcnn.py', 'data/tinygrad/models/retinanet.py', 'data/tinygrad/models/bert.py', 'data/tinygrad/models/convnext.py', 'data/tinygrad/models/rnnt.py', 'data/tinygrad/extra/export_model.py', 'data/tinygrad/examples/mlperf/model_spec.py', 'data/tinygrad/examples/mlperf/model_train.py', 'data/tinygrad/examples/mlperf/model_eval.py']\n",
      "Found 20 python files after filtering\n",
      "data/tinygrad/tinygrad/graph.py\n",
      "data/tinygrad/tinygrad/mlops.py\n",
      "data/tinygrad/tinygrad/realize.py\n",
      "data/tinygrad/tinygrad/tensor.py\n",
      "data/tinygrad/tinygrad/ops.py\n",
      "data/tinygrad/tinygrad/lazy.py\n",
      "data/tinygrad/tinygrad/helpers.py\n",
      "data/tinygrad/tinygrad/shape/symbolic.py\n",
      "data/tinygrad/tinygrad/shape/shapetracker.py\n",
      "data/tinygrad/tinygrad/shape/view.py\n",
      "data/tinygrad/tinygrad/nn/__init__.py\n",
      "data/tinygrad/tinygrad/nn/optim.py\n",
      "data/tinygrad/tinygrad/nn/state.py\n",
      "data/tinygrad/tinygrad/features/search.py\n",
      "data/tinygrad/tinygrad/features/image.py\n",
      "data/tinygrad/tinygrad/codegen/kernel.py\n",
      "data/tinygrad/tinygrad/codegen/linearizer.py\n",
      "data/tinygrad/models/resnet.py\n",
      "data/tinygrad/docs/abstractions.py\n",
      "data/tinygrad/examples/train_resnet.py\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# get all python files inside data/tinygrad even inside subfolders etc\n",
    "filepath = \"data/tinygrad/\"\n",
    "python_files = glob.glob(filepath + \"**/*.py\", recursive=True)\n",
    "print(f\"Found {len(python_files)} python files\")\n",
    "\n",
    "def is_usefull_python_file(python_file_path):\n",
    "    # just to remove useless file for the assistant \n",
    "    bad_strings_to_not_match = [\"test\", \"mlperf\", \"setup.py\",\n",
    "                                \"runtime\", \"examples\", \"renderer\",\n",
    "                                 \"openpilot\", \"models\",\"adreno\", \n",
    "                                 \"extra\", \"jit\", \"sz.py\"]\n",
    "    if \"resnet.py\" in python_file_path:\n",
    "        return True\n",
    "    for bad_string in bad_strings_to_not_match:\n",
    "        if bad_string in python_file_path:\n",
    "            return False\n",
    "    return True\n",
    "# print files with model in the path\n",
    "\n",
    "print(\"Files with model in the path\")\n",
    "print(list(filter(lambda x: \"model\" in x, python_files)))\n",
    "\n",
    "\n",
    "python_files = list(filter(is_usefull_python_file, python_files))\n",
    "print(f\"Found {len(python_files)} python files after filtering\")\n",
    "assert len(python_files) <= 20, \"Openai limit is 20 files\"\n",
    "print(\"\\n\".join(python_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the files to Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348d206b59564a33a05666fea974ffbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "client = OpenAI()\n",
    "uploaded_files = []\n",
    "for filename in tqdm(python_files):\n",
    "    file_obj = client.files.create(\n",
    "        file=open(filename, 'rb'),\n",
    "        purpose='assistants',\n",
    "        \n",
    "    )\n",
    "    uploaded_files.append(file_obj.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file-tBjLzvyBuP4dYop5FCSwuEtb',\n",
       " 'file-Kx0PfJUP7l04XkRZbtYVc16O',\n",
       " 'file-yVsLs62WAGRKYZZYsw3dOkls',\n",
       " 'file-eZcVjBZBNkGoaheSrMvqHz1b',\n",
       " 'file-i7ZYDFJRAVQhmtFyHhBi8BP7',\n",
       " 'file-VBf84l6dHvWynYZxWVFMYmT6',\n",
       " 'file-P6HtZVnisbqvIRR866bNCIuM',\n",
       " 'file-G2bffUxlxY90zBV3VIFCMTCc',\n",
       " 'file-hTxQ1IhuvXiF1fhQsfD5AXEJ',\n",
       " 'file-MGpQOsAJXhwZF2jTP75YvfFf',\n",
       " 'file-TKO1zhJIYtScKL4Ztr0aCO5h',\n",
       " 'file-opzlSYW2vHONow5h2a7C1Y8b',\n",
       " 'file-69YpFEWAwZB4lxQOs3EfgFQ0',\n",
       " 'file-Cp9OPRhTFfcXhoICHXCrZLW3',\n",
       " 'file-oqm4EHOwpTOjt9dYGSthuHrn',\n",
       " 'file-WuqoF7SwLYmjKLx5EuAV5JzO',\n",
       " 'file-5cDOsjWn9R95PZzxvtsvT28L',\n",
       " 'file-jv1zfst9aK8VYdkg7uTZB6re',\n",
       " 'file-f7lhFDJRKvvFgPxDmUMk6PuH',\n",
       " 'file-OSqH9D4JVi2WN59gsfxCI8Zn']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinygrad_assistant = openai.beta.assistants.create(\n",
    "    instructions=\"You are helping coders understand the tinygrad library. You have access to the source code of the codebase. You are a helpful tinygrad assistant.\",\n",
    "    name=\"Tinygrad Assistant (API)\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"retrieval\"}],\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    file_ids=uploaded_files,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an empty thread\n",
    "Empty threads are not linked to an assistant yet. Multiple assistants can be used inside the same thread :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = openai.beta.threads.create()\n",
    "thread_id = thread.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Explain Conv2d implementation in tinygrad. Return the corresponding Code for each explanation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Waiting 1sec\n",
      "Run completed in 00:00:16\n"
     ]
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread_id,\n",
    "    role=\"user\",\n",
    "    content=query,\n",
    ")\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread_id,\n",
    "    assistant_id=tinygrad_assistant.id)\n",
    "\n",
    "import time\n",
    "while True:\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)\n",
    "    if run.completed_at:\n",
    "        elapsed = run.completed_at - run.created_at\n",
    "        elapsed = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed))\n",
    "        print(f\"Run completed in {elapsed}\")\n",
    "        break\n",
    "    print(\"Waiting 1sec\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `Conv2d` class in tinygrad is defined with the following key components:\n",
      "\n",
      "### Initialization (`__init__` method)\n",
      "\n",
      "```python\n",
      "class Conv2d:\n",
      "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
      "    self.kernel_size = (kernel_size, kernel_size) if isinstance(kernel_size, int) else tuple(kernel_size)\n",
      "    self.stride, self.padding, self.dilation, self.groups = stride, padding, dilation, groups\n",
      "    self.weight = self.initialize_weight(out_channels, in_channels // groups, *self.kernel_size)\n",
      "    assert all_int(self.weight.shape), \"does not support symbolic shape\"\n",
      "    bound = 1 / math.sqrt(prod(self.weight.shape[1:]))\n",
      "    self.bias = Tensor.uniform(out_channels, low=-bound, high=bound) if bias else None\n",
      "```\n",
      "\n",
      "- The constructor takes several arguments such as the number of input channels (`in_channels`), the number of output channels (`out_channels`), the kernel size (`kernel_size`), stride, padding, dilation, and whether to use groups for grouped convolutions and whether to have a bias term.\n",
      "- The kernel size can be an integer, in which case it will be the same for both dimensions, or a tuple specifying the height and width.\n",
      "- The weights are initialized using the Kaiming uniform initialization method, which is suitable for ReLU activations to maintain the variance of the inputs through the layers.\n",
      "- The bias, if included, is initialized uniformly within a range calculated from the bounds of the weight's shape, ensuring a small starting value.\n",
      "  \n",
      "### Function Call (`__call__` method)\n",
      "\n",
      "```python\n",
      "  def __call__(self, x: Tensor):\n",
      "    return x.conv2d(self.weight, self.bias, padding=self.padding, stride=self.stride, dilation=self.dilation, groups=self.groups)\n",
      "```\n",
      "\n",
      "- The `__call__` method is executed when an instance of `Conv2d` is called like a function.\n",
      "- It takes an input tensor `x` and applies the 2D convolution operation using the previously initialized weights and biases along with the other parameters.\n",
      "- The actual convolution operation is invoked through the `conv2d` method of the input tensor `x`.\n",
      "\n",
      "### Weights Initialization\n",
      "\n",
      "```python\n",
      "  def initialize_weight(self, out_channels, in_channels, groups):\n",
      "    return Tensor.kaiming_uniform(out_channels, in_channels // groups * self.kernel_size, a=math.sqrt(5))\n",
      "```\n",
      "\n",
      "- This method is called during the initialization of the `Conv2d` object to set up the weights of the convolutional layer.\n",
      "- It uses the Kaiming uniform initializer with the number of output channels, the adjusted number of input channels based on the number of groups, and the kernel size to determine the correct shape of the weight tensor.\n",
      "  \n",
      "This snippet of code describes the `Conv2d` class present in the tinygrad library for implementing 2D convolutional layers in a neural network. It defines how the layer is structured, initialized, and how the forward pass is computed. The code is concise, focusing on the essential aspects of a convolutional layer.\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "last_message = messages.data[0]\n",
    "\n",
    "text = last_message.content[0].text.value\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
